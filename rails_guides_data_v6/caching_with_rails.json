[{"code":[],"body":"This is an introduction to three types of caching techniques: page, action and\nfragment caching. By default Rails provides fragment caching. In order to use\npage and action caching you will need to add actionpack-page_caching and\nactionpack-action_caching to your Gemfile.By default, caching is only enabled in your production environment. You can play\naround with caching locally by running rails dev:cache, or by setting\nconfig.action_controller.perform_caching to true in config/environments/development.rb.","title":"1 Basic Caching","anchor":"#basic-caching"},{"title":"1.1 Page Caching","anchor":"#page-caching","code":[],"body":"Page caching is a Rails mechanism which allows the request for a generated page\nto be fulfilled by the web server (i.e. Apache or NGINX) without having to go\nthrough the entire Rails stack. While this is super fast it can't be applied to\nevery situation (such as pages that need authentication). Also, because the\nweb server is serving a file directly from the filesystem you will need to\nimplement cache expiration."},{"title":"1.2 Action Caching","anchor":"#action-caching","code":[],"body":"Page Caching cannot be used for actions that have before filters - for example, pages that require authentication. This is where Action Caching comes in. Action Caching works like Page Caching except the incoming web request hits the Rails stack so that before filters can be run on it before the cache is served. This allows authentication and other restrictions to be run while still serving the result of the output from a cached copy."},{"title":"1.3 Fragment Caching","anchor":"#fragment-caching","code":["\n<% @products.each do |product| %>\n  <% cache product do %>\n    <%= render product %>\n  <% end %>\n<% end %>\n\n<% @products.each do |product| %>\n  <% cache product do %>\n    <%= render product %>\n  <% end %>\n<% end %>\n\nCopy\n","\nviews/products/index:bea67108094918eeba42cd4a6e786901/products/1\n\nviews/products/index:bea67108094918eeba42cd4a6e786901/products/1\n\nCopy\n","\n<% cache_if admin?, product do %>\n  <%= render product %>\n<% end %>\n\n<% cache_if admin?, product do %>\n  <%= render product %>\n<% end %>\n\nCopy\n"],"body":"Dynamic web applications usually build pages with a variety of components not\nall of which have the same caching characteristics. When different parts of the\npage need to be cached and expired separately you can use Fragment Caching.Fragment Caching allows a fragment of view logic to be wrapped in a cache block and served out of the cache store when the next request comes in.For example, if you wanted to cache each product on a page, you could use this\ncode:When your application receives its first request to this page, Rails will write\na new cache entry with a unique key. A key looks something like this:The string of characters in the middle is a template tree digest. It is a hash\ndigest computed based on the contents of the view fragment you are caching. If\nyou change the view fragment (e.g., the HTML changes), the digest will change,\nexpiring the existing file.A cache version, derived from the product record, is stored in the cache entry.\nWhen the product is touched, the cache version changes, and any cached fragments\nthat contain the previous version are ignored.If you want to cache a fragment under certain conditions, you can use\ncache_if or cache_unless:"},{"code":["\n<%= render partial: 'products/product', collection: @products, cached: true %>\n\n<%= render partial: 'products/product', collection: @products, cached: true %>\n\nCopy\n"],"body":"The render helper can also cache individual templates rendered for a collection.\nIt can even one up the previous example with each by reading all cache\ntemplates at once instead of one by one. This is done by passing cached: true when rendering the collection:All cached templates from previous renders will be fetched at once with much\ngreater speed. Additionally, the templates that haven't yet been cached will be\nwritten to cache and multi fetched on the next render.","title":"1.3.1 Collection caching","anchor":"#collection-caching"},{"title":"1.4 Russian Doll Caching","anchor":"#russian-doll-caching","code":["\n<% cache product do %>\n  <%= render product.games %>\n<% end %>\n\n<% cache product do %>\n  <%= render product.games %>\n<% end %>\n\nCopy\n","\n<% cache game do %>\n  <%= render game %>\n<% end %>\n\n<% cache game do %>\n  <%= render game %>\n<% end %>\n\nCopy\n","\nclass Product < ApplicationRecord\n  has_many :games\nend\n\nclass Game < ApplicationRecord\n  belongs_to :product, touch: true\nend\n\nclass Product < ApplicationRecord\n  has_many :games\nend\n\nclass Game < ApplicationRecord\n  belongs_to :product, touch: true\nend\n\nCopy\n"],"body":"You may want to nest cached fragments inside other cached fragments. This is\ncalled Russian doll caching.The advantage of Russian doll caching is that if a single product is updated,\nall the other inner fragments can be reused when regenerating the outer\nfragment.As explained in the previous section, a cached file will expire if the value of\nupdated_at changes for a record on which the cached file directly depends.\nHowever, this will not expire any cache the fragment is nested within.For example, take the following view:Which in turn renders this view:If any attribute of game is changed, the updated_at value will be set to the\ncurrent time, thereby expiring the cache. However, because updated_at\nwill not be changed for the product object, that cache will not be expired and\nyour app will serve stale data. To fix this, we tie the models together with\nthe touch method:With touch set to true, any action which changes updated_at for a game\nrecord will also change it for the associated product, thereby expiring the\ncache."},{"title":"1.5 Shared Partial Caching","anchor":"#shared-partial-caching","code":["\nrender(partial: 'hotels/hotel', collection: @hotels, cached: true)\n\nrender(partial: 'hotels/hotel', collection: @hotels, cached: true)\n\nCopy\n","\nrender(partial: 'hotels/hotel.html.erb', collection: @hotels, cached: true)\n\nrender(partial: 'hotels/hotel.html.erb', collection: @hotels, cached: true)\n\nCopy\n"],"body":"It is possible to share partials and associated caching between files with different mime types. For example shared partial caching allows template writers to share a partial between HTML and JavaScript files. When templates are collected in the template resolver file paths they only include the template language extension and not the mime type. Because of this templates can be used for multiple mime types. Both HTML and JavaScript requests will respond to the following code:Will load a file named hotels/hotel.erb.Another option is to include the full filename of the partial to render.Will load a file named hotels/hotel.html.erb in any file mime type, for example you could include this partial in a JavaScript file."},{"title":"1.6 Managing dependencies","anchor":"#managing-dependencies","code":[],"body":"In order to correctly invalidate the cache, you need to properly define the\ncaching dependencies. Rails is clever enough to handle common cases so you don't\nhave to specify anything. However, sometimes, when you're dealing with custom\nhelpers for instance, you need to explicitly define them."},{"title":"1.6.1 Implicit dependencies","anchor":"#implicit-dependencies","code":["\nrender partial: \"comments/comment\", collection: commentable.comments\nrender \"comments/comments\"\nrender 'comments/comments'\nrender('comments/comments')\n\nrender \"header\" translates to render(\"comments/header\")\n\nrender(@topic)         translates to render(\"topics/topic\")\nrender(topics)         translates to render(\"topics/topic\")\nrender(message.topics) translates to render(\"topics/topic\")\n\nrender partial: \"comments/comment\", collection: commentable.comments\nrender \"comments/comments\"\nrender 'comments/comments'\nrender('comments/comments')\n\nrender \"header\" translates to render(\"comments/header\")\n\nrender(@topic)         translates to render(\"topics/topic\")\nrender(topics)         translates to render(\"topics/topic\")\nrender(message.topics) translates to render(\"topics/topic\")\n\nCopy\n","\nrender @project.documents.where(published: true)\n\nrender @project.documents.where(published: true)\n\nCopy\n","\nrender partial: \"documents/document\", collection: @project.documents.where(published: true)\n\nrender partial: \"documents/document\", collection: @project.documents.where(published: true)\n\nCopy\n"],"body":"Most template dependencies can be derived from calls to render in the template\nitself. Here are some examples of render calls that ActionView::Digestor knows\nhow to decode:On the other hand, some calls need to be changed to make caching work properly.\nFor instance, if you're passing a custom collection, you'll need to change:to:"},{"code":["\n<%= render_sortable_todolists @project.todolists %>\n\n<%= render_sortable_todolists @project.todolists %>\n\nCopy\n","\n<%# Template Dependency: todolists/todolist %>\n<%= render_sortable_todolists @project.todolists %>\n\n<%# Template Dependency: todolists/todolist %>\n<%= render_sortable_todolists @project.todolists %>\n\nCopy\n","\n<%# Template Dependency: events/* %>\n<%= render_categorizable_events @person.events %>\n\n<%# Template Dependency: events/* %>\n<%= render_categorizable_events @person.events %>\n\nCopy\n","\n<%# Template Collection: notification %>\n<% my_helper_that_calls_cache(some_arg, notification) do %>\n  <%= notification.name %>\n<% end %>\n\n<%# Template Collection: notification %>\n<% my_helper_that_calls_cache(some_arg, notification) do %>\n  <%= notification.name %>\n<% end %>\n\nCopy\n"],"body":"Sometimes you'll have template dependencies that can't be derived at all. This\nis typically the case when rendering happens in helpers. Here's an example:You'll need to use a special comment format to call those out:In some cases, like a single table inheritance setup, you might have a bunch of\nexplicit dependencies. Instead of writing every template out, you can use a\nwildcard to match any template in a directory:As for collection caching, if the partial template doesn't start with a clean\ncache call, you can still benefit from collection caching by adding a special\ncomment format anywhere in the template, like:","title":"1.6.2 Explicit dependencies","anchor":"#explicit-dependencies"},{"code":["\n<%# Helper Dependency Updated: Jul 28, 2015 at 7pm %>\n<%= some_helper_method(person) %>\n\n<%# Helper Dependency Updated: Jul 28, 2015 at 7pm %>\n<%= some_helper_method(person) %>\n\nCopy\n"],"body":"If you use a helper method, for example, inside a cached block and you then update\nthat helper, you'll have to bump the cache as well. It doesn't really matter how\nyou do it, but the MD5 of the template file must change. One recommendation is to\nsimply be explicit in a comment, like:","title":"1.6.3 External dependencies","anchor":"#external-dependencies"},{"code":["\nclass Product < ApplicationRecord\n  def competing_price\n    Rails.cache.fetch(\"#{cache_key_with_version}/competing_price\", expires_in: 12.hours) do\n      Competitor::API.find_price(id)\n    end\n  end\nend\n\nclass Product < ApplicationRecord\n  def competing_price\n    Rails.cache.fetch(\"#{cache_key_with_version}/competing_price\", expires_in: 12.hours) do\n      Competitor::API.find_price(id)\n    end\n  end\nend\n\nCopy\n"],"body":"Sometimes you need to cache a particular value or query result instead of caching view fragments. Rails' caching mechanism works great for storing any kind of information.The most efficient way to implement low-level caching is using the Rails.cache.fetch method. This method does both reading and writing to the cache. When passed only a single argument, the key is fetched and value from the cache is returned. If a block is passed, that block will be executed in the event of a cache miss. The return value of the block will be written to the cache under the given cache key, and that return value will be returned. In case of cache hit, the cached value will be returned without executing the block.Consider the following example. An application has a Product model with an instance method that looks up the product's price on a competing website. The data returned by this method would be perfect for low-level caching:","title":"1.7 Low-Level Caching","anchor":"#low-level-caching"},{"title":"1.8 SQL Caching","anchor":"#sql-caching","code":["\nclass ProductsController < ApplicationController\n\n  def index\n    # Run a find query\n    @products = Product.all\n\n    # ...\n\n    # Run the same query again\n    @products = Product.all\n  end\n\nend\n\nclass ProductsController < ApplicationController\n\n  def index\n    # Run a find query\n    @products = Product.all\n\n    # ...\n\n    # Run the same query again\n    @products = Product.all\n  end\n\nend\n\nCopy\n"],"body":"Query caching is a Rails feature that caches the result set returned by each\nquery. If Rails encounters the same query again for that request, it will use\nthe cached result set as opposed to running the query against the database\nagain.For example:The second time the same query is run against the database, it's not actually going to hit the database. The first time the result is returned from the query it is stored in the query cache (in memory) and the second time it's pulled from memory.However, it's important to note that query caches are created at the start of\nan action and destroyed at the end of that action and thus persist only for the\nduration of the action. If you'd like to store query results in a more\npersistent fashion, you can with low level caching."},{"title":"2 Cache Stores","anchor":"#cache-stores","code":[],"body":"Rails provides different stores for the cached data (apart from SQL and page\ncaching)."},{"title":"2.1 Configuration","anchor":"#configuration","code":["\nconfig.cache_store = :memory_store, { size: 64.megabytes }\n\nconfig.cache_store = :memory_store, { size: 64.megabytes }\n\nCopy\n"],"body":"You can set up your application's default cache store by setting the\nconfig.cache_store configuration option. Other parameters can be passed as\narguments to the cache store's constructor:You can access the cache by calling Rails.cache."},{"title":"2.2 ActiveSupport::Cache::Store","anchor":"#activesupport-cache-store","code":[],"body":"This class provides the foundation for interacting with the cache in Rails. This is an abstract class and you cannot use it on its own. Rather you must use a concrete implementation of the class tied to a storage engine. Rails ships with several implementations documented below.The main methods to call are read, write, delete, exist?, and fetch. The fetch method takes a block and will either return an existing value from the cache, or evaluate the block and write the result to the cache if no value exists.There are some common options that can be used by all cache implementations. These can be passed to the constructor or the various methods to interact with entries."},{"code":["\ngem 'connection_pool'\n\ngem 'connection_pool'\n\nCopy\n","\nconfig.cache_store = :mem_cache_store, \"cache.example.com\", { pool_size: 5, pool_timeout: 5 }\n\nconfig.cache_store = :mem_cache_store, \"cache.example.com\", { pool_size: 5, pool_timeout: 5 }\n\nCopy\n"],"body":"By default the MemCacheStore and RedisCacheStore use a single connection\nper process. This means that if you're using Puma, or another threaded server,\nyou can have multiple threads waiting for the connection to become available.\nTo increase the number of available connections you can enable connection\npooling.First, add the connection_pool gem to your Gemfile:Next, pass the :pool_size and/or :pool_timeout options when configuring the cache store:","title":"2.2.1 Connection Pool Options","anchor":"#connection-pool-options"},{"code":["\nconfig.cache_store = MyCacheStore.new\n\nconfig.cache_store = MyCacheStore.new\n\nCopy\n"],"body":"You can create your own custom cache store by simply extending\nActiveSupport::Cache::Store and implementing the appropriate methods. This way,\nyou can swap in any number of caching technologies into your Rails application.To use a custom cache store, simply set the cache store to a new instance of your\ncustom class.","title":"2.2.2 Custom Cache Stores","anchor":"#custom-cache-stores"},{"code":["\nconfig.cache_store = :memory_store, { size: 64.megabytes }\n\nconfig.cache_store = :memory_store, { size: 64.megabytes }\n\nCopy\n"],"body":"This cache store keeps entries in memory in the same Ruby process. The cache\nstore has a bounded size specified by sending the :size option to the\ninitializer (default is 32Mb). When the cache exceeds the allotted size, a\ncleanup will occur and the least recently used entries will be removed.If you're running multiple Ruby on Rails server processes (which is the case\nif you're using Phusion Passenger or puma clustered mode), then your Rails server\nprocess instances won't be able to share cache data with each other. This cache\nstore is not appropriate for large application deployments. However, it can\nwork well for small, low traffic sites with only a couple of server processes,\nas well as development and test environments.New Rails projects are configured to use this implementation in development environment by default.","title":"2.3 ActiveSupport::Cache::MemoryStore","anchor":"#activesupport-cache-memorystore"},{"title":"2.4 ActiveSupport::Cache::FileStore","anchor":"#activesupport-cache-filestore","code":["\nconfig.cache_store = :file_store, \"/path/to/cache/directory\"\n\nconfig.cache_store = :file_store, \"/path/to/cache/directory\"\n\nCopy\n"],"body":"This cache store uses the file system to store entries. The path to the directory where the store files will be stored must be specified when initializing the cache.With this cache store, multiple server processes on the same host can share a\ncache. This cache store is appropriate for low to medium traffic sites that are\nserved off one or two hosts. Server processes running on different hosts could\nshare a cache by using a shared file system, but that setup is not recommended.As the cache will grow until the disk is full, it is recommended to\nperiodically clear out old entries.This is the default cache store implementation (at \"#{root}/tmp/cache/\") if\nno explicit config.cache_store is supplied."},{"title":"2.5 ActiveSupport::Cache::MemCacheStore","anchor":"#activesupport-cache-memcachestore","code":["\nconfig.cache_store = :mem_cache_store, \"cache-1.example.com\", \"cache-2.example.com\"\n\nconfig.cache_store = :mem_cache_store, \"cache-1.example.com\", \"cache-2.example.com\"\n\nCopy\n","\nconfig.cache_store = :mem_cache_store # Will fallback to $MEMCACHE_SERVERS, then 127.0.0.1:11211\n\nconfig.cache_store = :mem_cache_store # Will fallback to $MEMCACHE_SERVERS, then 127.0.0.1:11211\n\nCopy\n"],"body":"This cache store uses Danga's memcached server to provide a centralized cache for your application. Rails uses the bundled dalli gem by default. This is currently the most popular cache store for production websites. It can be used to provide a single, shared cache cluster with very high performance and redundancy.When initializing the cache, you should specify the addresses for all memcached servers in your cluster, or ensure the MEMCACHE_SERVERS environment variable has been set appropriately.If neither are specified, it will assume memcached is running on localhost on the default port (127.0.0.1:11211), but this is not an ideal setup for larger sites.See the Dalli::Client documentation for supported address types.The write and fetch methods on this cache accept two additional options that take advantage of features specific to memcached. You can specify :raw to send a value directly to the server with no serialization. The value must be a string or number. You can use memcached direct operations like increment and decrement only on raw values. You can also specify :unless_exist if you don't want memcached to overwrite an existing entry."},{"title":"2.6 ActiveSupport::Cache::RedisCacheStore","anchor":"#activesupport-cache-rediscachestore","code":["\ngem 'redis'\n\ngem 'redis'\n\nCopy\n","\ngem 'hiredis'\n\ngem 'hiredis'\n\nCopy\n","\nconfig.cache_store = :redis_cache_store, { url: ENV['REDIS_URL'] }\n\nconfig.cache_store = :redis_cache_store, { url: ENV['REDIS_URL'] }\n\nCopy\n","\ncache_servers = %w(redis://cache-01:6379/0 redis://cache-02:6379/0)\nconfig.cache_store = :redis_cache_store, { url: cache_servers,\n\n  connect_timeout:    30,  # Defaults to 20 seconds\n  read_timeout:       0.2, # Defaults to 1 second\n  write_timeout:      0.2, # Defaults to 1 second\n  reconnect_attempts: 1,   # Defaults to 0\n\n  error_handler: -> (method:, returning:, exception:) {\n    # Report errors to Sentry as warnings\n    Raven.capture_exception exception, level: 'warning',\n      tags: { method: method, returning: returning }\n  }\n}\n\ncache_servers = %w(redis://cache-01:6379/0 redis://cache-02:6379/0)\nconfig.cache_store = :redis_cache_store, { url: cache_servers,\n\n  connect_timeout:    30,  # Defaults to 20 seconds\n  read_timeout:       0.2, # Defaults to 1 second\n  write_timeout:      0.2, # Defaults to 1 second\n  reconnect_attempts: 1,   # Defaults to 0\n\n  error_handler: -> (method:, returning:, exception:) {\n    # Report errors to Sentry as warnings\n    Raven.capture_exception exception, level: 'warning',\n      tags: { method: method, returning: returning }\n  }\n}\n\nCopy\n"],"body":"The Redis cache store takes advantage of Redis support for automatic eviction\nwhen it reaches max memory, allowing it to behave much like a Memcached cache server.Deployment note: Redis doesn't expire keys by default, so take care to use a\ndedicated Redis cache server. Don't fill up your persistent-Redis server with\nvolatile cache data! Read the\nRedis cache server setup guide in detail.For a cache-only Redis server, set maxmemory-policy to one of the variants of allkeys.\nRedis 4+ supports least-frequently-used eviction (allkeys-lfu), an excellent\ndefault choice. Redis 3 and earlier should use least-recently-used eviction (allkeys-lru).Set cache read and write timeouts relatively low. Regenerating a cached value\nis often faster than waiting more than a second to retrieve it. Both read and\nwrite timeouts default to 1 second, but may be set lower if your network is\nconsistently low-latency.By default, the cache store will not attempt to reconnect to Redis if the\nconnection fails during a request. If you experience frequent disconnects you\nmay wish to enable reconnect attempts.Cache reads and writes never raise exceptions; they just return nil instead,\nbehaving as if there was nothing in the cache. To gauge whether your cache is\nhitting exceptions, you may provide an error_handler to report to an\nexception gathering service. It must accept three keyword arguments: method,\nthe cache store method that was originally called; returning, the value that\nwas returned to the user, typically nil; and exception, the exception that\nwas rescued.To get started, add the redis gem to your Gemfile:You can enable support for the faster hiredis\nconnection library by additionally adding its ruby wrapper to your Gemfile:Redis cache store will automatically require and use hiredis if available. No further\nconfiguration is needed.Finally, add the configuration in the relevant config/environments/*.rb file:A more complex, production Redis cache store may look something like this:"},{"code":["\nconfig.cache_store = :null_store\n\nconfig.cache_store = :null_store\n\nCopy\n"],"body":"This cache store implementation is meant to be used only in development or test environments and it never stores anything. This can be very useful in development when you have code that interacts directly with Rails.cache but caching may interfere with being able to see the results of code changes. With this cache store, all fetch and read operations will result in a miss.","title":"2.7 ActiveSupport::Cache::NullStore","anchor":"#activesupport-cache-nullstore"},{"code":["\n# This is a legal cache key\nRails.cache.read(site: \"mysite\", owners: [owner_1, owner_2])\n\n# This is a legal cache key\nRails.cache.read(site: \"mysite\", owners: [owner_1, owner_2])\n\nCopy\n"],"body":"The keys used in a cache can be any object that responds to either cache_key or\nto_param. You can implement the cache_key method on your classes if you need\nto generate custom keys. Active Record will generate keys based on the class name\nand record id.You can use Hashes and Arrays of values as cache keys.The keys you use on Rails.cache will not be the same as those actually used with\nthe storage engine. They may be modified with a namespace or altered to fit\ntechnology backend constraints. This means, for instance, that you can't save\nvalues with Rails.cache and then try to pull them out with the dalli gem.\nHowever, you also don't need to worry about exceeding the memcached size limit or\nviolating syntax rules.","title":"3 Cache Keys","anchor":"#cache-keys"},{"title":"4 Conditional GET support","anchor":"#conditional-get-support","code":["\nclass ProductsController < ApplicationController\n\n  def show\n    @product = Product.find(params[:id])\n\n    # If the request is stale according to the given timestamp and etag value\n    # (i.e. it needs to be processed again) then execute this block\n    if stale?(last_modified: @product.updated_at.utc, etag: @product.cache_key_with_version)\n      respond_to do |wants|\n        # ... normal response processing\n      end\n    end\n\n    # If the request is fresh (i.e. it's not modified) then you don't need to do\n    # anything. The default render checks for this using the parameters\n    # used in the previous call to stale? and will automatically send a\n    # :not_modified. So that's it, you're done.\n  end\nend\n\nclass ProductsController < ApplicationController\n\n  def show\n    @product = Product.find(params[:id])\n\n    # If the request is stale according to the given timestamp and etag value\n    # (i.e. it needs to be processed again) then execute this block\n    if stale?(last_modified: @product.updated_at.utc, etag: @product.cache_key_with_version)\n      respond_to do |wants|\n        # ... normal response processing\n      end\n    end\n\n    # If the request is fresh (i.e. it's not modified) then you don't need to do\n    # anything. The default render checks for this using the parameters\n    # used in the previous call to stale? and will automatically send a\n    # :not_modified. So that's it, you're done.\n  end\nend\n\nCopy\n","\nclass ProductsController < ApplicationController\n  def show\n    @product = Product.find(params[:id])\n\n    if stale?(@product)\n      respond_to do |wants|\n        # ... normal response processing\n      end\n    end\n  end\nend\n\nclass ProductsController < ApplicationController\n  def show\n    @product = Product.find(params[:id])\n\n    if stale?(@product)\n      respond_to do |wants|\n        # ... normal response processing\n      end\n    end\n  end\nend\n\nCopy\n","\nclass ProductsController < ApplicationController\n\n  # This will automatically send back a :not_modified if the request is fresh,\n  # and will render the default template (product.*) if it's stale.\n\n  def show\n    @product = Product.find(params[:id])\n    fresh_when last_modified: @product.published_at.utc, etag: @product\n  end\nend\n\nclass ProductsController < ApplicationController\n\n  # This will automatically send back a :not_modified if the request is fresh,\n  # and will render the default template (product.*) if it's stale.\n\n  def show\n    @product = Product.find(params[:id])\n    fresh_when last_modified: @product.published_at.utc, etag: @product\n  end\nend\n\nCopy\n","\nclass HomeController < ApplicationController\n  def index\n    http_cache_forever(public: true) do\n      render\n    end\n  end\nend\n\nclass HomeController < ApplicationController\n  def index\n    http_cache_forever(public: true) do\n      render\n    end\n  end\nend\n\nCopy\n"],"body":"Conditional GETs are a feature of the HTTP specification that provide a way for web servers to tell browsers that the response to a GET request hasn't changed since the last request and can be safely pulled from the browser cache.They work by using the HTTP_IF_NONE_MATCH and HTTP_IF_MODIFIED_SINCE headers to pass back and forth both a unique content identifier and the timestamp of when the content was last changed. If the browser makes a request where the content identifier (etag) or last modified since timestamp matches the server's version then the server only needs to send back an empty response with a not modified status.It is the server's (i.e. our) responsibility to look for a last modified timestamp and the if-none-match header and determine whether or not to send back the full response. With conditional-get support in Rails this is a pretty easy task:Instead of an options hash, you can also simply pass in a model. Rails will use the updated_at and cache_key_with_version methods for setting last_modified and etag:If you don't have any special response processing and are using the default rendering mechanism (i.e. you're not using respond_to or calling render yourself) then you've got an easy helper in fresh_when:Sometimes we want to cache response, for example a static page, that never gets\nexpired. To achieve this, we can use http_cache_forever helper and by doing\nso browser and proxies will cache it indefinitely.By default cached responses will be private, cached only on the user's web\nbrowser. To allow proxies to cache the response, set public: true to indicate\nthat they can serve the cached response to all users.Using this helper, last_modified header is set to Time.new(2011, 1, 1).utc\nand expires header is set to a 100 years."},{"code":["\nW/\"618bbc92e2d35ea1945008b42799b0e7\" → Weak ETag\n\"618bbc92e2d35ea1945008b42799b0e7\" → Strong ETag\n\nW/\"618bbc92e2d35ea1945008b42799b0e7\" → Weak ETag\n\"618bbc92e2d35ea1945008b42799b0e7\" → Strong ETag\n\nCopy\n","\nclass ProductsController < ApplicationController\n  def show\n    @product = Product.find(params[:id])\n    fresh_when last_modified: @product.published_at.utc, strong_etag: @product\n  end\nend\n\nclass ProductsController < ApplicationController\n  def show\n    @product = Product.find(params[:id])\n    fresh_when last_modified: @product.published_at.utc, strong_etag: @product\n  end\nend\n\nCopy\n","\nresponse.strong_etag = response.body # => \"618bbc92e2d35ea1945008b42799b0e7\"\n\nresponse.strong_etag = response.body # => \"618bbc92e2d35ea1945008b42799b0e7\"\n\nCopy\n"],"body":"Rails generates weak ETags by default. Weak ETags allow semantically equivalent\nresponses to have the same ETags, even if their bodies do not match exactly.\nThis is useful when we don't want the page to be regenerated for minor changes in\nresponse body.Weak ETags have a leading W/ to differentiate them from strong ETags.Unlike weak ETag, strong ETag implies that response should be exactly the same\nand byte by byte identical. Useful when doing Range requests within a\nlarge video or PDF file. Some CDNs support only strong ETags, like Akamai.\nIf you absolutely need to generate a strong ETag, it can be done as follows.You can also set the strong ETag directly on the response.","title":"4.1 Strong v/s Weak ETags","anchor":"#strong-v-s-weak-etags"},{"code":["\n$ bin/rails dev:cache\nDevelopment mode is now being cached.\n$ bin/rails dev:cache\nDevelopment mode is no longer being cached.\n\nbin/rails dev:cache\nbin/rails dev:cache\n\nCopy\n"],"body":"It's common to want to test the caching strategy of your application\nin development mode. Rails provides the rails command dev:cache to\neasily toggle caching on/off.","title":"5 Caching in Development","anchor":"#caching-in-development"},{"code":[],"body":"","title":"6 References","anchor":"#references"}]