[{"code":[],"body":"Active Storage facilitates uploading files to a cloud storage service like\nAmazon S3, Google Cloud Storage, or Microsoft Azure Storage and attaching those\nfiles to Active Record objects. It comes with a local disk-based service for\ndevelopment and testing and supports mirroring files to subordinate services for\nbackups and migrations.Using Active Storage, an application can transform image uploads with\nImageMagick, generate image representations of\nnon-image uploads like PDFs and videos, and extract metadata from arbitrary\nfiles.","title":"1 What is Active Storage?","anchor":"#what-is-active-storage-questionmark"},{"title":"2 Setup","anchor":"#setup","code":["\nlocal:\n  service: Disk\n  root: <%= Rails.root.join(\"storage\") %>\n\ntest:\n  service: Disk\n  root: <%= Rails.root.join(\"tmp/storage\") %>\n\namazon:\n  service: S3\n  access_key_id: \"\"\n  secret_access_key: \"\"\n  bucket: \"\"\n  region: \"\" # e.g. 'us-east-1'\n\nlocal:\n  service: Disk\n  root: <%= Rails.root.join(\"storage\") %>\n\ntest:\n  service: Disk\n  root: <%= Rails.root.join(\"tmp/storage\") %>\n\namazon:\n  service: S3\n  access_key_id: \"\"\n  secret_access_key: \"\"\n  bucket: \"\"\n  region: \"\" # e.g. 'us-east-1'\n\nCopy\n","\n# Store files locally.\nconfig.active_storage.service = :local\n\n# Store files locally.\nconfig.active_storage.service = :local\n\nCopy\n","\n# Store files on Amazon S3.\nconfig.active_storage.service = :amazon\n\n# Store files on Amazon S3.\nconfig.active_storage.service = :amazon\n\nCopy\n","\n# Store uploaded files on the local file system in a temporary directory.\nconfig.active_storage.service = :test\n\n# Store uploaded files on the local file system in a temporary directory.\nconfig.active_storage.service = :test\n\nCopy\n"],"body":"Active Storage uses two tables in your applicationâ€™s database named\nactive_storage_blobs and active_storage_attachments. After creating a new\napplication (or upgrading your application to Rails 5.2), run\nbin/rails active_storage:install to generate a migration that creates these\ntables. Use bin/rails db:migrate to run the migration.Declare Active Storage services in config/storage.yml. For each service your\napplication uses, provide a name and the requisite configuration. The example\nbelow declares three services named local, test, and amazon:Tell Active Storage which service to use by setting\nRails.application.config.active_storage.service. Because each environment will\nlikely use a different service, it is recommended to do this on a\nper-environment basis. To use the disk service from the previous example in the\ndevelopment environment, you would add the following to\nconfig/environments/development.rb:To use the S3 service in production, you add the following to\nconfig/environments/production.rb:To use the test service when testing, you add the following to\nconfig/environments/test.rb:Continue reading for more information on the built-in service adapters (e.g.\nDisk and S3) and the configuration they require."},{"title":"2.1 Disk Service","anchor":"#disk-service","code":["\nlocal:\n  service: Disk\n  root: <%= Rails.root.join(\"storage\") %>\n\nlocal:\n  service: Disk\n  root: <%= Rails.root.join(\"storage\") %>\n\nCopy\n"],"body":"Declare a Disk service in config/storage.yml:"},{"code":["\namazon:\n  service: S3\n  access_key_id: \"\"\n  secret_access_key: \"\"\n  region: \"\"\n  bucket: \"\"\n\namazon:\n  service: S3\n  access_key_id: \"\"\n  secret_access_key: \"\"\n  region: \"\"\n  bucket: \"\"\n\nCopy\n","\namazon:\n  service: S3\n  access_key_id: \"\"\n  secret_access_key: \"\"\n  region: \"\"\n  bucket: \"\"\n  http_open_timeout: 0\n  http_read_timeout: 0\n  retry_limit: 0\n  upload:\n    server_side_encryption: \"\" # 'aws:kms' or 'AES256'\n\namazon:\n  service: S3\n  access_key_id: \"\"\n  secret_access_key: \"\"\n  region: \"\"\n  bucket: \"\"\n  http_open_timeout: 0\n  http_read_timeout: 0\n  retry_limit: 0\n  upload:\n    server_side_encryption: \"\" # 'aws:kms' or 'AES256'\n\nCopy\n","\ngem \"aws-sdk-s3\", require: false\n\ngem \"aws-sdk-s3\", require: false\n\nCopy\n","\ndigitalocean:\n  service: S3\n  endpoint: https://nyc3.digitaloceanspaces.com\n  access_key_id: ...\n  secret_access_key: ...\n  # ...and other options\n\ndigitalocean:\n  service: S3\n  endpoint: https://nyc3.digitaloceanspaces.com\n  access_key_id: ...\n  secret_access_key: ...\n  # ...and other options\n\nCopy\n"],"body":"To connect to Amazon S3, declare an S3 service in config/storage.yml:Optionally provide client and upload options:Add the aws-sdk-s3 gem to your Gemfile:To connect to an S3-compatible object storage API such as DigitalOcean Spaces, provide the endpoint:","title":"2.2 S3 Service (Amazon S3 and S3-compatible APIs)","anchor":"#s3-service-amazon-s3-and-s3-compatible-apis"},{"code":["\nazure:\n  service: AzureStorage\n  storage_account_name: \"\"\n  storage_access_key: \"\"\n  container: \"\"\n\nazure:\n  service: AzureStorage\n  storage_account_name: \"\"\n  storage_access_key: \"\"\n  container: \"\"\n\nCopy\n","\ngem \"azure-storage-blob\", require: false\n\ngem \"azure-storage-blob\", require: false\n\nCopy\n"],"body":"Declare an Azure Storage service in config/storage.yml:Add the azure-storage-blob gem to your Gemfile:","title":"2.3 Microsoft Azure Storage Service","anchor":"#microsoft-azure-storage-service"},{"code":["\ngoogle:\n  service: GCS\n  credentials: <%= Rails.root.join(\"path/to/keyfile.json\") %>\n  project: \"\"\n  bucket: \"\"\n\ngoogle:\n  service: GCS\n  credentials: <%= Rails.root.join(\"path/to/keyfile.json\") %>\n  project: \"\"\n  bucket: \"\"\n\nCopy\n","\ngoogle:\n  service: GCS\n  credentials:\n    type: \"service_account\"\n    project_id: \"\"\n    private_key_id: <%= Rails.application.credentials.dig(:gcs, :private_key_id) %>\n    private_key: <%= Rails.application.credentials.dig(:gcs, :private_key).dump %>\n    client_email: \"\"\n    client_id: \"\"\n    auth_uri: \"https://accounts.google.com/o/oauth2/auth\"\n    token_uri: \"https://accounts.google.com/o/oauth2/token\"\n    auth_provider_x509_cert_url: \"https://www.googleapis.com/oauth2/v1/certs\"\n    client_x509_cert_url: \"\"\n  project: \"\"\n  bucket: \"\"\n\ngoogle:\n  service: GCS\n  credentials:\n    type: \"service_account\"\n    project_id: \"\"\n    private_key_id: <%= Rails.application.credentials.dig(:gcs, :private_key_id) %>\n    private_key: <%= Rails.application.credentials.dig(:gcs, :private_key).dump %>\n    client_email: \"\"\n    client_id: \"\"\n    auth_uri: \"https://accounts.google.com/o/oauth2/auth\"\n    token_uri: \"https://accounts.google.com/o/oauth2/token\"\n    auth_provider_x509_cert_url: \"https://www.googleapis.com/oauth2/v1/certs\"\n    client_x509_cert_url: \"\"\n  project: \"\"\n  bucket: \"\"\n\nCopy\n","\ngem \"google-cloud-storage\", \"~> 1.11\", require: false\n\ngem \"google-cloud-storage\", \"~> 1.11\", require: false\n\nCopy\n"],"body":"Declare a Google Cloud Storage service in config/storage.yml:Optionally provide a Hash of credentials instead of a keyfile path:Add the google-cloud-storage gem to your Gemfile:","title":"2.4 Google Cloud Storage Service","anchor":"#google-cloud-storage-service"},{"code":["\ns3_west_coast:\n  service: S3\n  access_key_id: \"\"\n  secret_access_key: \"\"\n  region: \"\"\n  bucket: \"\"\n\ns3_east_coast:\n  service: S3\n  access_key_id: \"\"\n  secret_access_key: \"\"\n  region: \"\"\n  bucket: \"\"\n\nproduction:\n  service: Mirror\n  primary: s3_east_coast\n  mirrors:\n    - s3_west_coast\n\ns3_west_coast:\n  service: S3\n  access_key_id: \"\"\n  secret_access_key: \"\"\n  region: \"\"\n  bucket: \"\"\n\ns3_east_coast:\n  service: S3\n  access_key_id: \"\"\n  secret_access_key: \"\"\n  region: \"\"\n  bucket: \"\"\n\nproduction:\n  service: Mirror\n  primary: s3_east_coast\n  mirrors:\n    - s3_west_coast\n\nCopy\n"],"body":"You can keep multiple services in sync by defining a mirror service. A mirror\nservice replicates uploads and deletes across two or more subordinate services.A mirror service is intended to be used temporarily during a migration between\nservices in production. You can start mirroring to a new service, copy\npre-existing files from the old service to the new, then go all-in on the new\nservice.Define each of the services you'd like to mirror as described above. Reference\nthem by name when defining a mirror service:Although all secondary services receive uploads, downloads are always handled\nby the primary service.Mirror services are compatible with direct uploads. New files are directly\nuploaded to the primary service. When a directly-uploaded file is attached to a\nrecord, a background job is enqueued to copy it to the secondary services.","title":"2.5 Mirror Service","anchor":"#mirror-service"},{"title":"2.6 Public access","anchor":"#public-access","code":["\ngcs: &gcs\n  service: GCS\n  project: \"\"\n\nprivate_gcs:\n  <<: *gcs\n  credentials: <%= Rails.root.join(\"path/to/private_keyfile.json\") %>\n  bucket: \"\"\n\npublic_gcs:\n  <<: *gcs\n  credentials: <%= Rails.root.join(\"path/to/public_keyfile.json\") %>\n  bucket: \"\"\n  public: true\n\ngcs: &gcs\n  service: GCS\n  project: \"\"\n\nprivate_gcs:\n  <<: *gcs\n  credentials: <%= Rails.root.join(\"path/to/private_keyfile.json\") %>\n  bucket: \"\"\n\npublic_gcs:\n  <<: *gcs\n  credentials: <%= Rails.root.join(\"path/to/public_keyfile.json\") %>\n  bucket: \"\"\n  public: true\n\nCopy\n"],"body":"By default, Active Storage assumes private access to services. This means generating signed, single-use URLs for blobs. If you'd rather make blobs publicly accessible, specify public: true in your app's config/storage.yml:Make sure your buckets are properly configured for public access. See docs on how to enable public read permissions for Amazon S3, Google Cloud Storage, and Microsoft Azure storage services. Amazon S3 additionally requires that you have the s3:PutObjectAcl permission.When converting an existing application to use public: true, make sure to update every individual file in the bucket to be publicly-readable before switching over."},{"title":"3 Attaching Files to Records","anchor":"#attaching-files-to-records","code":[],"body":""},{"title":"3.1 has_one_attached","anchor":"#has-one-attached","code":["\nclass User < ApplicationRecord\n  has_one_attached :avatar\nend\n\nclass User < ApplicationRecord\n  has_one_attached :avatar\nend\n\nCopy\n","\n<%= form.file_field :avatar %>\n\n<%= form.file_field :avatar %>\n\nCopy\n","\nclass SignupController < ApplicationController\n  def create\n    user = User.create!(user_params)\n    session[:user_id] = user.id\n    redirect_to root_path\n  end\n\n  private\n    def user_params\n      params.require(:user).permit(:email_address, :password, :avatar)\n    end\nend\n\nclass SignupController < ApplicationController\n  def create\n    user = User.create!(user_params)\n    session[:user_id] = user.id\n    redirect_to root_path\n  end\n\n  private\n    def user_params\n      params.require(:user).permit(:email_address, :password, :avatar)\n    end\nend\n\nCopy\n","\nuser.avatar.attach(params[:avatar])\n\nuser.avatar.attach(params[:avatar])\n\nCopy\n","\nuser.avatar.attached?\n\nuser.avatar.attached?\n\nCopy\n","\nclass User < ApplicationRecord\n  has_one_attached :avatar, service: :s3\nend\n\nclass User < ApplicationRecord\n  has_one_attached :avatar, service: :s3\nend\n\nCopy\n"],"body":"The has_one_attached macro sets up a one-to-one mapping between records and\nfiles. Each record can have one file attached to it.For example, suppose your application has a User model. If you want each user to\nhave an avatar, define the User model like this:You can create a user with an avatar:Call avatar.attach to attach an avatar to an existing user:Call avatar.attached? to determine whether a particular user has an avatar:In some cases you might want to override a default service for a specific attachment.\nYou can configure specific services per attachment using the service option:"},{"code":["\nclass Message < ApplicationRecord\n  has_many_attached :images\nend\n\nclass Message < ApplicationRecord\n  has_many_attached :images\nend\n\nCopy\n","\nclass MessagesController < ApplicationController\n  def create\n    message = Message.create!(message_params)\n    redirect_to message\n  end\n\n  private\n    def message_params\n      params.require(:message).permit(:title, :content, images: [])\n    end\nend\n\nclass MessagesController < ApplicationController\n  def create\n    message = Message.create!(message_params)\n    redirect_to message\n  end\n\n  private\n    def message_params\n      params.require(:message).permit(:title, :content, images: [])\n    end\nend\n\nCopy\n","\n@message.images.attach(params[:images])\n\n@message.images.attach(params[:images])\n\nCopy\n","\n@message.images.attached?\n\n@message.images.attached?\n\nCopy\n","\nclass Message < ApplicationRecord\n  has_many_attached :images, service: :s3\nend\n\nclass Message < ApplicationRecord\n  has_many_attached :images, service: :s3\nend\n\nCopy\n"],"body":"The has_many_attached macro sets up a one-to-many relationship between records\nand files. Each record can have many files attached to it.For example, suppose your application has a Message model. If you want each\nmessage to have many images, define the Message model like this:You can create a message with images:Call images.attach to add new images to an existing message:Call images.attached? to determine whether a particular message has any images:Overriding the default service is done the same way as has_one_attached, by using the service option:","title":"3.2 has_many_attached","anchor":"#has-many-attached"},{"code":["\n@message.image.attach(io: File.open('/path/to/file'), filename: 'file.pdf')\n\n@message.image.attach(io: File.open('/path/to/file'), filename: 'file.pdf')\n\nCopy\n","\n@message.image.attach(io: File.open('/path/to/file'), filename: 'file.pdf', content_type: 'application/pdf')\n\n@message.image.attach(io: File.open('/path/to/file'), filename: 'file.pdf', content_type: 'application/pdf')\n\nCopy\n","\n@message.image.attach(\n  io: File.open('/path/to/file'),\n  filename: 'file.pdf',\n  content_type: 'application/pdf',\n  identify: false\n)\n\n@message.image.attach(\n  io: File.open('/path/to/file'),\n  filename: 'file.pdf',\n  content_type: 'application/pdf',\n  identify: false\n)\n\nCopy\n"],"body":"Sometimes you need to attach a file that doesnâ€™t arrive via an HTTP request.\nFor example, you may want to attach a file you generated on disk or downloaded\nfrom a user-submitted URL. You may also want to attach a fixture file in a\nmodel test. To do that, provide a Hash containing at least an open IO object\nand a filename:When possible, provide a content type as well. Active Storage attempts to\ndetermine a fileâ€™s content type from its data. It falls back to the content\ntype you provide if it canâ€™t do that.You can bypass the content type inference from the data by passing in\nidentify: false along with the content_type.If you donâ€™t provide a content type and Active Storage canâ€™t determine the\nfileâ€™s content type automatically, it defaults to application/octet-stream.","title":"3.3 Attaching File/IO Objects","anchor":"#attaching-file-io-objects"},{"title":"4 Removing Files","anchor":"#removing-files","code":["\n# Synchronously destroy the avatar and actual resource files.\nuser.avatar.purge\n\n# Destroy the associated models and actual resource files async, via Active Job.\nuser.avatar.purge_later\n\n# Synchronously destroy the avatar and actual resource files.\nuser.avatar.purge\n\n# Destroy the associated models and actual resource files async, via Active Job.\nuser.avatar.purge_later\n\nCopy\n"],"body":"To remove an attachment from a model, call purge on the\nattachment. If your application is set up to use Active Job, removal can be done\nin the background instead by calling purge_later.\nPurging deletes the blob and the file from the storage service."},{"code":["\nurl_for(user.avatar)\n\nurl_for(user.avatar)\n\nCopy\n","\nrails_blob_path(user.avatar, disposition: \"attachment\")\n\nrails_blob_path(user.avatar, disposition: \"attachment\")\n\nCopy\n","\nRails.application.routes.url_helpers.rails_blob_path(user.avatar, only_path: true)\n\nRails.application.routes.url_helpers.rails_blob_path(user.avatar, only_path: true)\n\nCopy\n"],"body":"Generate a permanent URL for the blob that points to the application. Upon\naccess, a redirect to the actual service endpoint is returned. This indirection\ndecouples the service URL from the actual one, and allows, for example, mirroring\nattachments in different services for high-availability. The redirection has an\nHTTP expiration of 5 minutes.To create a download link, use the rails_blob_{path|url} helper. Using this\nhelper allows you to set the disposition.If you need to create a link from outside of controller/view context (Background\njobs, Cronjobs, etc.), you can access the rails_blob_path like this:","title":"5 Linking to Files","anchor":"#linking-to-files"},{"code":["\nbinary = user.avatar.download\n\nbinary = user.avatar.download\n\nCopy\n","\nmessage.video.open do |file|\n  system '/path/to/virus/scanner', file.path\n  # ...\nend\n\nmessage.video.open do |file|\n  system '/path/to/virus/scanner', file.path\n  # ...\nend\n\nCopy\n"],"body":"Sometimes you need to process a blob after itâ€™s uploadedâ€”for example, to convert\nit to a different format. Use the attachment's download method to read a blobâ€™s\nbinary data into memory:You might want to download a blob to a file on disk so an external program (e.g.\na virus scanner or media transcoder) can operate on it. Use the attachment's\nopen method to download a blob to a tempfile on disk:It's important to know that the file is not yet available in the after_create callback but in the after_create_commit only.","title":"6 Downloading Files","anchor":"#downloading-files"},{"title":"7 Analyzing Files","anchor":"#analyzing-files","code":[],"body":"Active Storage analyzes files once they've been uploaded by queuing a job in Active Job. Analyzed files will store additional information in the metadata hash, including analyzed: true. You can check whether a blob has been analyzed by calling analyzed? on it.Image analysis provides width and height attributes. Video analysis provides these, as well as duration, angle, and display_aspect_ratio.Analysis requires the mini_magick gem. Video analysis also requires the FFmpeg library, which you must include separately."},{"title":"8 Transforming Images","anchor":"#transforming-images","code":["\ngem 'image_processing'\n\ngem 'image_processing'\n\nCopy\n","\n<%= image_tag user.avatar.variant(resize_to_limit: [100, 100]) %>\n\n<%= image_tag user.avatar.variant(resize_to_limit: [100, 100]) %>\n\nCopy\n","\n# Use Vips for processing variants.\nconfig.active_storage.variant_processor = :vips\n\n# Use Vips for processing variants.\nconfig.active_storage.variant_processor = :vips\n\nCopy\n"],"body":"To enable variants, add the image_processing gem to your Gemfile:To create a variation of an image, call variant on the attachment. You can pass any transformation to the method supported by the processor. The default processor for Active Storage is MiniMagick, but you can also use Vips.When the browser hits the variant URL, Active Storage will lazily transform the\noriginal blob into the specified format and redirect to its new service\nlocation.To switch to the Vips processor, you would add the following to\nconfig/application.rb:"},{"code":["\n<ul>\n  <% @message.files.each do |file| %>\n    <li>\n      <%= image_tag file.preview(resize_to_limit: [100, 100]) %>\n    </li>\n  <% end %>\n</ul>\n\n<ul>\n  <% @message.files.each do |file| %>\n    <li>\n      <%= image_tag file.preview(resize_to_limit: [100, 100]) %>\n    </li>\n  <% end %>\n</ul>\n\nCopy\n"],"body":"Some non-image files can be previewed: that is, they can be presented as images.\nFor example, a video file can be previewed by extracting its first frame. Out of\nthe box, Active Storage supports previewing videos and PDF documents. To create\na link to a lazily-generated preview, use the attachment's preview method:","title":"9 Previewing Files","anchor":"#previewing-files"},{"title":"10 Direct Uploads","anchor":"#direct-uploads","code":[],"body":"Active Storage, with its included JavaScript library, supports uploading\ndirectly from the client to the cloud."},{"title":"10.1 Usage","anchor":"#usage","code":[],"body":""},{"code":[],"body":"To make direct uploads to a third-party service work, youâ€™ll need to configure the service to allow cross-origin requests from your app. Consult the CORS documentation for your service:Take care to allow:No CORS configuration is required for the Disk service since it shares your appâ€™s origin.","title":"10.2 Cross-Origin Resource Sharing (CORS) configuration","anchor":"#cross-origin-resource-sharing-cors-configuration"},{"title":"10.2.1 Example: S3 CORS configuration","anchor":"#example-s3-cors-configuration","code":["\n[\n  {\n    \"AllowedHeaders\": [\n      \"*\"\n    ],\n    \"AllowedMethods\": [\n      \"PUT\"\n    ],\n    \"AllowedOrigins\": [\n      \"https://www.example.com\"\n    ],\n    \"ExposeHeaders\": [\n      \"Origin\",\n      \"Content-Type\",\n      \"Content-MD5\",\n      \"Content-Disposition\"\n    ],\n    \"MaxAgeSeconds\": 3600\n  }\n]\n\n[\n  {\n    \"AllowedHeaders\": [\n      \"*\"\n    ],\n    \"AllowedMethods\": [\n      \"PUT\"\n    ],\n    \"AllowedOrigins\": [\n      \"https://www.example.com\"\n    ],\n    \"ExposeHeaders\": [\n      \"Origin\",\n      \"Content-Type\",\n      \"Content-MD5\",\n      \"Content-Disposition\"\n    ],\n    \"MaxAgeSeconds\": 3600\n  }\n]\n\nCopy\n"],"body":""},{"code":["\n[\n  {\n    \"origin\": [\"https://www.example.com\"],\n    \"method\": [\"PUT\"],\n    \"responseHeader\": [\"Origin\", \"Content-Type\", \"Content-MD5\", \"Content-Disposition\"],\n    \"maxAgeSeconds\": 3600\n  }\n]\n\n[\n  {\n    \"origin\": [\"https://www.example.com\"],\n    \"method\": [\"PUT\"],\n    \"responseHeader\": [\"Origin\", \"Content-Type\", \"Content-MD5\", \"Content-Disposition\"],\n    \"maxAgeSeconds\": 3600\n  }\n]\n\nCopy\n"],"body":"","title":"10.2.2 Example: Google Cloud Storage CORS configuration","anchor":"#example-google-cloud-storage-cors-configuration"},{"code":["\n<Cors>\n  <CorsRule>\n    <AllowedOrigins>https://www.example.com</AllowedOrigins>\n    <AllowedMethods>PUT</AllowedMethods>\n    <AllowedHeaders>Origin, Content-Type, Content-MD5, x-ms-blob-content-disposition, x-ms-blob-type</AllowedHeaders>\n    <MaxAgeInSeconds>3600</MaxAgeInSeconds>\n  </CorsRule>\n<Cors>\n\n<Cors>\n  <CorsRule>\n    <AllowedOrigins>https://www.example.com</AllowedOrigins>\n    <AllowedMethods>PUT</AllowedMethods>\n    <AllowedHeaders>Origin, Content-Type, Content-MD5, x-ms-blob-content-disposition, x-ms-blob-type</AllowedHeaders>\n    <MaxAgeInSeconds>3600</MaxAgeInSeconds>\n  </CorsRule>\n<Cors>\n\nCopy\n"],"body":"","title":"10.2.3 Example: Azure Storage CORS configuration","anchor":"#example-azure-storage-cors-configuration"},{"code":[],"body":"","title":"10.3 Direct upload JavaScript events","anchor":"#direct-upload-javascript-events"},{"code":["\n// direct_uploads.js\n\naddEventListener(\"direct-upload:initialize\", event => {\n  const { target, detail } = event\n  const { id, file } = detail\n  target.insertAdjacentHTML(\"beforebegin\", `\n    <div id=\"direct-upload-${id}\" class=\"direct-upload direct-upload--pending\">\n      <div id=\"direct-upload-progress-${id}\" class=\"direct-upload__progress\" style=\"width: 0%\"></div>\n      <span class=\"direct-upload__filename\"></span>\n    </div>\n  `)\n  target.previousElementSibling.querySelector(`.direct-upload__filename`).textContent = file.name\n})\n\naddEventListener(\"direct-upload:start\", event => {\n  const { id } = event.detail\n  const element = document.getElementById(`direct-upload-${id}`)\n  element.classList.remove(\"direct-upload--pending\")\n})\n\naddEventListener(\"direct-upload:progress\", event => {\n  const { id, progress } = event.detail\n  const progressElement = document.getElementById(`direct-upload-progress-${id}`)\n  progressElement.style.width = `${progress}%`\n})\n\naddEventListener(\"direct-upload:error\", event => {\n  event.preventDefault()\n  const { id, error } = event.detail\n  const element = document.getElementById(`direct-upload-${id}`)\n  element.classList.add(\"direct-upload--error\")\n  element.setAttribute(\"title\", error)\n})\n\naddEventListener(\"direct-upload:end\", event => {\n  const { id } = event.detail\n  const element = document.getElementById(`direct-upload-${id}`)\n  element.classList.add(\"direct-upload--complete\")\n})\n\n// direct_uploads.js\n\naddEventListener(\"direct-upload:initialize\", event => {\n  const { target, detail } = event\n  const { id, file } = detail\n  target.insertAdjacentHTML(\"beforebegin\", `\n    <div id=\"direct-upload-${id}\" class=\"direct-upload direct-upload--pending\">\n      <div id=\"direct-upload-progress-${id}\" class=\"direct-upload__progress\" style=\"width: 0%\"></div>\n      <span class=\"direct-upload__filename\"></span>\n    </div>\n  `)\n  target.previousElementSibling.querySelector(`.direct-upload__filename`).textContent = file.name\n})\n\naddEventListener(\"direct-upload:start\", event => {\n  const { id } = event.detail\n  const element = document.getElementById(`direct-upload-${id}`)\n  element.classList.remove(\"direct-upload--pending\")\n})\n\naddEventListener(\"direct-upload:progress\", event => {\n  const { id, progress } = event.detail\n  const progressElement = document.getElementById(`direct-upload-progress-${id}`)\n  progressElement.style.width = `${progress}%`\n})\n\naddEventListener(\"direct-upload:error\", event => {\n  event.preventDefault()\n  const { id, error } = event.detail\n  const element = document.getElementById(`direct-upload-${id}`)\n  element.classList.add(\"direct-upload--error\")\n  element.setAttribute(\"title\", error)\n})\n\naddEventListener(\"direct-upload:end\", event => {\n  const { id } = event.detail\n  const element = document.getElementById(`direct-upload-${id}`)\n  element.classList.add(\"direct-upload--complete\")\n})\n\nCopy\n","\n/* direct_uploads.css */\n\n.direct-upload {\n  display: inline-block;\n  position: relative;\n  padding: 2px 4px;\n  margin: 0 3px 3px 0;\n  border: 1px solid rgba(0, 0, 0, 0.3);\n  border-radius: 3px;\n  font-size: 11px;\n  line-height: 13px;\n}\n\n.direct-upload--pending {\n  opacity: 0.6;\n}\n\n.direct-upload__progress {\n  position: absolute;\n  top: 0;\n  left: 0;\n  bottom: 0;\n  opacity: 0.2;\n  background: #0076ff;\n  transition: width 120ms ease-out, opacity 60ms 60ms ease-in;\n  transform: translate3d(0, 0, 0);\n}\n\n.direct-upload--complete .direct-upload__progress {\n  opacity: 0.4;\n}\n\n.direct-upload--error {\n  border-color: red;\n}\n\ninput[type=file][data-direct-upload-url][disabled] {\n  display: none;\n}\n\n/* direct_uploads.css */\n\n.direct-upload {\n  display: inline-block;\n  position: relative;\n  padding: 2px 4px;\n  margin: 0 3px 3px 0;\n  border: 1px solid rgba(0, 0, 0, 0.3);\n  border-radius: 3px;\n  font-size: 11px;\n  line-height: 13px;\n}\n\n.direct-upload--pending {\n  opacity: 0.6;\n}\n\n.direct-upload__progress {\n  position: absolute;\n  top: 0;\n  left: 0;\n  bottom: 0;\n  opacity: 0.2;\n  background: #0076ff;\n  transition: width 120ms ease-out, opacity 60ms 60ms ease-in;\n  transform: translate3d(0, 0, 0);\n}\n\n.direct-upload--complete .direct-upload__progress {\n  opacity: 0.4;\n}\n\n.direct-upload--error {\n  border-color: red;\n}\n\ninput[type=file][data-direct-upload-url][disabled] {\n  display: none;\n}\n\nCopy\n"],"body":"You can use these events to show the progress of an upload.To show the uploaded files in a form:Add styles:","title":"10.4 Example","anchor":"#example"},{"code":["\nimport { DirectUpload } from \"@rails/activestorage\"\n\nconst input = document.querySelector('input[type=file]')\n\n// Bind to file drop - use the ondrop on a parent element or use a\n//  library like Dropzone\nconst onDrop = (event) => {\n  event.preventDefault()\n  const files = event.dataTransfer.files;\n  Array.from(files).forEach(file => uploadFile(file))\n}\n\n// Bind to normal file selection\ninput.addEventListener('change', (event) => {\n  Array.from(input.files).forEach(file => uploadFile(file))\n  // you might clear the selected files from the input\n  input.value = null\n})\n\nconst uploadFile = (file) => {\n  // your form needs the file_field direct_upload: true, which\n  //  provides data-direct-upload-url\n  const url = input.dataset.directUploadUrl\n  const upload = new DirectUpload(file, url)\n\n  upload.create((error, blob) => {\n    if (error) {\n      // Handle the error\n    } else {\n      // Add an appropriately-named hidden input to the form with a\n      //  value of blob.signed_id so that the blob ids will be\n      //  transmitted in the normal upload flow\n      const hiddenField = document.createElement('input')\n      hiddenField.setAttribute(\"type\", \"hidden\");\n      hiddenField.setAttribute(\"value\", blob.signed_id);\n      hiddenField.name = input.name\n      document.querySelector('form').appendChild(hiddenField)\n    }\n  })\n}\n\nimport { DirectUpload } from \"@rails/activestorage\"\n\nconst input = document.querySelector('input[type=file]')\n\n// Bind to file drop - use the ondrop on a parent element or use a\n//  library like Dropzone\nconst onDrop = (event) => {\n  event.preventDefault()\n  const files = event.dataTransfer.files;\n  Array.from(files).forEach(file => uploadFile(file))\n}\n\n// Bind to normal file selection\ninput.addEventListener('change', (event) => {\n  Array.from(input.files).forEach(file => uploadFile(file))\n  // you might clear the selected files from the input\n  input.value = null\n})\n\nconst uploadFile = (file) => {\n  // your form needs the file_field direct_upload: true, which\n  //  provides data-direct-upload-url\n  const url = input.dataset.directUploadUrl\n  const upload = new DirectUpload(file, url)\n\n  upload.create((error, blob) => {\n    if (error) {\n      // Handle the error\n    } else {\n      // Add an appropriately-named hidden input to the form with a\n      //  value of blob.signed_id so that the blob ids will be\n      //  transmitted in the normal upload flow\n      const hiddenField = document.createElement('input')\n      hiddenField.setAttribute(\"type\", \"hidden\");\n      hiddenField.setAttribute(\"value\", blob.signed_id);\n      hiddenField.name = input.name\n      document.querySelector('form').appendChild(hiddenField)\n    }\n  })\n}\n\nCopy\n","\nimport { DirectUpload } from \"@rails/activestorage\"\n\nclass Uploader {\n  constructor(file, url) {\n    this.upload = new DirectUpload(this.file, this.url, this)\n  }\n\n  upload(file) {\n    this.upload.create((error, blob) => {\n      if (error) {\n        // Handle the error\n      } else {\n        // Add an appropriately-named hidden input to the form\n        // with a value of blob.signed_id\n      }\n    })\n  }\n\n  directUploadWillStoreFileWithXHR(request) {\n    request.upload.addEventListener(\"progress\",\n      event => this.directUploadDidProgress(event))\n  }\n\n  directUploadDidProgress(event) {\n    // Use event.loaded and event.total to update the progress bar\n  }\n}\n\nimport { DirectUpload } from \"@rails/activestorage\"\n\nclass Uploader {\n  constructor(file, url) {\n    this.upload = new DirectUpload(this.file, this.url, this)\n  }\n\n  upload(file) {\n    this.upload.create((error, blob) => {\n      if (error) {\n        // Handle the error\n      } else {\n        // Add an appropriately-named hidden input to the form\n        // with a value of blob.signed_id\n      }\n    })\n  }\n\n  directUploadWillStoreFileWithXHR(request) {\n    request.upload.addEventListener(\"progress\",\n      event => this.directUploadDidProgress(event))\n  }\n\n  directUploadDidProgress(event) {\n    // Use event.loaded and event.total to update the progress bar\n  }\n}\n\nCopy\n"],"body":"If you want to use the Direct Upload feature from a JavaScript framework, or\nyou want to integrate custom drag and drop solutions, you can use the\nDirectUpload class for this purpose. Upon receiving a file from your library\nof choice, instantiate a DirectUpload and call its create method. Create takes\na callback to invoke when the upload completes.If you need to track the progress of the file upload, you can pass a third\nparameter to the DirectUpload constructor. During the upload, DirectUpload\nwill call the object's directUploadWillStoreFileWithXHR method. You can then\nbind your own progress handler on the XHR.","title":"10.5 Integrating with Libraries or Frameworks","anchor":"#integrating-with-libraries-or-frameworks"},{"code":["\nclass ApplicationSystemTestCase < ActionDispatch::SystemTestCase\n  driven_by :selenium, using: :chrome, screen_size: [1400, 1400]\n\n  def remove_uploaded_files\n    FileUtils.rm_rf(\"#{Rails.root}/storage_test\")\n  end\n\n  def after_teardown\n    super\n    remove_uploaded_files\n  end\nend\n\nclass ApplicationSystemTestCase < ActionDispatch::SystemTestCase\n  driven_by :selenium, using: :chrome, screen_size: [1400, 1400]\n\n  def remove_uploaded_files\n    FileUtils.rm_rf(\"#{Rails.root}/storage_test\")\n  end\n\n  def after_teardown\n    super\n    remove_uploaded_files\n  end\nend\n\nCopy\n","\n# Use inline job processing to make things happen immediately\nconfig.active_job.queue_adapter = :inline\n\n# Separate file storage in the test environment\nconfig.active_storage.service = :local_test\n\n# Use inline job processing to make things happen immediately\nconfig.active_job.queue_adapter = :inline\n\n# Separate file storage in the test environment\nconfig.active_storage.service = :local_test\n\nCopy\n"],"body":"System tests clean up test data by rolling back a transaction. Because destroy\nis never called on an object, the attached files are never cleaned up. If you\nwant to clear the files, you can do it in an after_teardown callback. Doing it\nhere ensures that all connections created during the test are complete and\nyou won't receive an error from Active Storage saying it can't find a file.If your system tests verify the deletion of a model with attachments and you're\nusing Active Job, set your test environment to use the inline queue adapter so\nthe purge job is executed immediately rather at an unknown time in the future.You may also want to use a separate service definition for the test environment\nso your tests don't delete the files you create during development.","title":"11 Discarding Files Stored During System Tests","anchor":"#discarding-files-stored-during-system-tests"},{"code":["\nmodule RemoveUploadedFiles\n  def after_teardown\n    super\n    remove_uploaded_files\n  end\n\n  private\n\n  def remove_uploaded_files\n    FileUtils.rm_rf(Rails.root.join('tmp', 'storage'))\n  end\nend\n\nmodule ActionDispatch\n  class IntegrationTest\n    prepend RemoveUploadedFiles\n  end\nend\n\nmodule RemoveUploadedFiles\n  def after_teardown\n    super\n    remove_uploaded_files\n  end\n\n  private\n\n  def remove_uploaded_files\n    FileUtils.rm_rf(Rails.root.join('tmp', 'storage'))\n  end\nend\n\nmodule ActionDispatch\n  class IntegrationTest\n    prepend RemoveUploadedFiles\n  end\nend\n\nCopy\n"],"body":"Similarly to System Tests, files uploaded during Integration Tests will not be\nautomatically cleaned up. If you want to clear the files, you can do it in an\nafter_teardown callback. Doing it here ensures that all connections created\nduring the test are complete and you won't receive an error from Active Storage\nsaying it can't find a file.","title":"12 Discarding Files Stored During Integration Tests","anchor":"#discarding-files-stored-during-integration-tests"},{"code":[],"body":"If you need to support a cloud service other than these, you will need to\nimplement the Service. Each service extends\nActiveStorage::Service\nby implementing the methods necessary to upload and download files to the cloud.","title":"13 Implementing Support for Other Cloud Services","anchor":"#implementing-support-for-other-cloud-services"}]